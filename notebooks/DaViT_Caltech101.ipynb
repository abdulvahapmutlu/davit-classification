{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7d7b90-d02d-4efa-b8e9-26534229be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\offic\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431643b4-2d5f-4ce7-9e62-ac4985f9ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"C:/Users/offic/OneDrive/Masaüstü/datasets/caltech-101\"\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for DaViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7fc5e6-305a-46d7-83ce-4d7d868f5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DaViT model from Timm\n",
    "model = timm.create_model('davit_tiny', pretrained=True)\n",
    "num_features = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),  # Pool to 1x1 spatial size\n",
    "    nn.Flatten(),             # Flatten the tensor\n",
    "    nn.Linear(num_features, len(dataset.classes))  # Adjust for Caltech-101 classes\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return torch.sum(preds == labels).item() / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8306cab9-209a-48a3-ae5a-0cf1af56265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8531, Accuracy: 0.7936, Val Loss: 0.6183, Val Accuracy: 0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.2835, Accuracy: 0.9232, Val Loss: 0.5421, Val Accuracy: 0.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.1885, Accuracy: 0.9500, Val Loss: 0.5220, Val Accuracy: 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.1874, Accuracy: 0.9500, Val Loss: 0.4614, Val Accuracy: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.1266, Accuracy: 0.9650, Val Loss: 0.3313, Val Accuracy: 0.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.1386, Accuracy: 0.9619, Val Loss: 0.4811, Val Accuracy: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.1024, Accuracy: 0.9739, Val Loss: 0.4315, Val Accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0194, Accuracy: 0.9948, Val Loss: 0.2620, Val Accuracy: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0019, Accuracy: 0.9995, Val Loss: 0.2620, Val Accuracy: 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0015, Accuracy: 0.9995, Val Loss: 0.2626, Val Accuracy: 0.9420\n"
     ]
    }
   ],
   "source": [
    "#Training the model.\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Progress bar for the current epoch\n",
    "    epoch_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
    "\n",
    "    for images, labels in epoch_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += calculate_accuracy(outputs, labels) * labels.size(0)\n",
    "\n",
    "        # Update progress bar with current metrics\n",
    "        epoch_bar.set_postfix({\n",
    "            'loss': running_loss/total_train,\n",
    "            'accuracy': running_corrects/total_train\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / total_train\n",
    "    epoch_acc = running_corrects / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            val_running_corrects += calculate_accuracy(outputs, labels) * labels.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / total_val\n",
    "    val_acc = val_running_corrects / total_val\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d74284-c7a4-4c98-b67c-5a4c6b6dfc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9420\n",
      "Overall Precision: 0.9457\n",
      "Unweighted Average Recall (UAR): 0.9243\n",
      "Overall F1-Score: 0.9415\n"
     ]
    }
   ],
   "source": [
    "y_true = all_labels\n",
    "y_pred = all_preds\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculating the metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "uar = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {precision:.4f}\")\n",
    "print(f\"Unweighted Average Recall (UAR): {uar:.4f}\")\n",
    "print(f\"Overall F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deda3ce6-5bf3-48bf-81c7-4e135a1f9521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "BACKGROUND_Google       0.82      0.81      0.82       102\n",
      "            Faces       0.99      1.00      0.99        95\n",
      "       Faces_easy       1.00      0.99      0.99        86\n",
      "         Leopards       1.00      1.00      1.00        30\n",
      "       Motorbikes       1.00      1.00      1.00       162\n",
      "        accordion       1.00      1.00      1.00         9\n",
      "        airplanes       0.98      1.00      0.99       161\n",
      "           anchor       1.00      0.67      0.80        12\n",
      "              ant       0.90      0.90      0.90        10\n",
      "           barrel       0.89      1.00      0.94         8\n",
      "             bass       1.00      0.92      0.96        13\n",
      "           beaver       0.75      0.82      0.78        11\n",
      "        binocular       1.00      1.00      1.00         3\n",
      "           bonsai       0.98      1.00      0.99        40\n",
      "            brain       0.90      0.95      0.92        19\n",
      "     brontosaurus       0.67      0.67      0.67         6\n",
      "           buddha       0.82      1.00      0.90        14\n",
      "        butterfly       1.00      0.94      0.97        18\n",
      "           camera       1.00      0.91      0.95        11\n",
      "           cannon       1.00      0.67      0.80        12\n",
      "         car_side       1.00      1.00      1.00        21\n",
      "      ceiling_fan       1.00      0.88      0.94        17\n",
      "        cellphone       1.00      0.83      0.91         6\n",
      "            chair       0.83      0.91      0.87        11\n",
      "       chandelier       0.87      1.00      0.93        20\n",
      "      cougar_body       0.85      0.85      0.85        13\n",
      "      cougar_face       1.00      0.87      0.93        15\n",
      "             crab       0.93      0.68      0.79        19\n",
      "         crayfish       0.90      0.60      0.72        15\n",
      "        crocodile       0.67      0.80      0.73        10\n",
      "   crocodile_head       0.67      0.57      0.62         7\n",
      "              cup       1.00      0.80      0.89        15\n",
      "        dalmatian       0.94      1.00      0.97        16\n",
      "      dollar_bill       1.00      0.94      0.97        16\n",
      "          dolphin       1.00      1.00      1.00        17\n",
      "        dragonfly       1.00      1.00      1.00        17\n",
      "  electric_guitar       1.00      0.94      0.97        18\n",
      "         elephant       0.93      0.93      0.93        14\n",
      "              emu       1.00      0.82      0.90        11\n",
      "        euphonium       1.00      0.80      0.89         5\n",
      "             ewer       1.00      1.00      1.00        12\n",
      "            ferry       0.87      1.00      0.93        13\n",
      "         flamingo       1.00      1.00      1.00        10\n",
      "    flamingo_head       0.86      1.00      0.92         6\n",
      "         garfield       1.00      0.88      0.93         8\n",
      "          gerenuk       1.00      0.90      0.95        10\n",
      "       gramophone       0.92      1.00      0.96        12\n",
      "      grand_piano       1.00      1.00      1.00        16\n",
      "        hawksbill       1.00      1.00      1.00        18\n",
      "        headphone       0.83      0.83      0.83         6\n",
      "         hedgehog       0.88      0.88      0.88         8\n",
      "       helicopter       0.87      1.00      0.93        13\n",
      "             ibis       0.96      1.00      0.98        22\n",
      "     inline_skate       1.00      1.00      1.00         7\n",
      "      joshua_tree       0.92      0.92      0.92        13\n",
      "         kangaroo       0.82      1.00      0.90        14\n",
      "            ketch       0.91      0.95      0.93        22\n",
      "             lamp       1.00      1.00      1.00        12\n",
      "           laptop       1.00      1.00      1.00        17\n",
      "            llama       0.91      1.00      0.95        10\n",
      "          lobster       0.79      0.73      0.76        15\n",
      "            lotus       0.70      0.50      0.58        14\n",
      "         mandolin       1.00      0.77      0.87        13\n",
      "           mayfly       0.82      1.00      0.90         9\n",
      "          menorah       1.00      0.95      0.97        20\n",
      "        metronome       1.00      1.00      1.00         6\n",
      "          minaret       0.83      0.91      0.87        11\n",
      "         nautilus       0.67      0.80      0.73         5\n",
      "          octopus       0.58      0.88      0.70         8\n",
      "            okapi       1.00      1.00      1.00        10\n",
      "           pagoda       1.00      1.00      1.00        15\n",
      "            panda       1.00      1.00      1.00         5\n",
      "           pigeon       1.00      1.00      1.00        15\n",
      "            pizza       0.88      1.00      0.93         7\n",
      "         platypus       0.50      1.00      0.67         1\n",
      "          pyramid       0.86      0.86      0.86         7\n",
      "         revolver       1.00      1.00      1.00        20\n",
      "            rhino       0.91      0.91      0.91        11\n",
      "          rooster       0.92      1.00      0.96        11\n",
      "        saxophone       1.00      1.00      1.00         6\n",
      "         schooner       0.93      0.93      0.93        14\n",
      "         scissors       1.00      1.00      1.00         7\n",
      "         scorpion       0.82      1.00      0.90         9\n",
      "        sea_horse       1.00      1.00      1.00        10\n",
      "           snoopy       0.88      1.00      0.93         7\n",
      "      soccer_ball       1.00      0.92      0.96        12\n",
      "          stapler       0.83      1.00      0.91         5\n",
      "         starfish       1.00      1.00      1.00        15\n",
      "      stegosaurus       1.00      1.00      1.00        11\n",
      "        stop_sign       1.00      1.00      1.00         9\n",
      "       strawberry       0.75      1.00      0.86         6\n",
      "        sunflower       1.00      1.00      1.00        22\n",
      "             tick       1.00      1.00      1.00         7\n",
      "        trilobite       1.00      1.00      1.00        14\n",
      "         umbrella       1.00      0.94      0.97        16\n",
      "            watch       1.00      1.00      1.00        42\n",
      "      water_lilly       0.55      0.60      0.57        10\n",
      "       wheelchair       0.93      1.00      0.96        13\n",
      "         wild_cat       1.00      1.00      1.00         4\n",
      "    windsor_chair       1.00      0.93      0.97        15\n",
      "           wrench       0.62      0.83      0.71         6\n",
      "         yin_yang       1.00      1.00      1.00        12\n",
      "\n",
      "         accuracy                           0.94      1829\n",
      "        macro avg       0.92      0.92      0.92      1829\n",
      "     weighted avg       0.95      0.94      0.94      1829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07bbcf23-f77e-45cf-b9d9-52743ba861ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'davit_caltech101.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
